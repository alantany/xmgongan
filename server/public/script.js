// JavaScript for chat functionality will go here.
// For example, handling input, sending messages to a backend, and displaying responses.

document.addEventListener('DOMContentLoaded', () => {
    const inputField = document.querySelector('.input-area input[type="text"]');
    const sendButton = document.getElementById('send-button');
    const micButton = document.getElementById('mic-button');
    const chatArea = document.getElementById('chat-area');
    const uploadFileButton = document.getElementById('upload-file-button');
    const fileUploadInput = document.getElementById('file-upload-input');
    const selectedFilesContainer = document.getElementById('selected-files-container');
    const newConversationBtn = document.getElementById('new-conversation-btn');

    let selectedFiles = []; // Store selected files
    let isFileListExpanded = false; // Track if the full file list is shown
    const maxInitialFilesToShow = 2;
    
    // å¯¹è¯å†å²è®°å½•ï¼Œå­˜å‚¨å®Œæ•´çš„æ¶ˆæ¯å†å²
    let conversationHistory = [];

    // æ™ºèƒ½ä¸Šä¸‹æ–‡é•¿åº¦ç®¡ç†å‡½æ•°
    function estimateTokens(text) {
        // ç²—ç•¥ä¼°ç®—ï¼šä¸­æ–‡å­—ç¬¦çº¦1-2ä¸ªtokenï¼Œè‹±æ–‡å•è¯çº¦1.3ä¸ªtokenï¼Œæ ‡ç‚¹å’Œç©ºæ ¼çº¦0.3ä¸ªtoken
        if (typeof text !== 'string') return 0;
        
        const chineseChars = (text.match(/[\u4e00-\u9fff]/g) || []).length;
        const englishWords = (text.match(/[a-zA-Z]+/g) || []).length;
        const otherChars = text.length - chineseChars - englishWords;
        
        return Math.ceil(chineseChars * 1.5 + englishWords * 1.3 + otherChars * 0.3);
    }

    function getMessageTokenCount(message) {
        if (typeof message.content === 'string') {
            return estimateTokens(message.content);
        } else if (Array.isArray(message.content)) {
            return message.content.reduce((total, part) => {
                if (part.type === 'text') {
                    return total + estimateTokens(part.text || '');
                }
                return total;
            }, 0);
        }
        return 0;
    }

    function getTotalTokens(messages) {
        return messages.reduce((total, msg) => total + getMessageTokenCount(msg), 0);
    }

    function manageContextLength(history, maxTokens) {
        if (history.length === 0) return history;
        
        let totalTokens = getTotalTokens(history);
        console.log(`å½“å‰å¯¹è¯å†å²tokenæ•°: ${totalTokens}, æœ€å¤§é™åˆ¶: ${maxTokens}`);
        
        if (totalTokens <= maxTokens) {
            return history;
        }
        
        // è®¡ç®—éœ€è¦åˆ é™¤çš„tokenæ•°é‡
        const tokensToRemove = totalTokens - maxTokens;
        console.log(`éœ€è¦åˆ é™¤çº¦ ${tokensToRemove} tokens`);
        
        // æ–°ç­–ç•¥ï¼šç¡®ä¿æœ€æ–°å¯¹è¯ä¼˜å…ˆçº§æœ€é«˜ï¼Œé¿å…è¢«æ–‡ä»¶å†…å®¹"ç»‘æ¶"
        const messageAnalysis = history.map((msg, idx) => {
            const tokens = getMessageTokenCount(msg);
            const isFileMessage = isMessageContainingFile(msg);
            const distanceFromEnd = history.length - 1 - idx; // 0è¡¨ç¤ºæœ€æ–°æ¶ˆæ¯
            
            // é‡æ–°è®¾è®¡ä¼˜å…ˆçº§ï¼šè·ç¦»å½“å‰è¶Šè¿‘ä¼˜å…ˆçº§è¶Šé«˜
            let priority;
            if (distanceFromEnd === 0) {
                // æœ€æ–°ç”¨æˆ·é—®é¢˜ï¼šç»å¯¹æœ€é«˜ä¼˜å…ˆçº§
                priority = 10;
            } else if (distanceFromEnd === 1) {
                // æœ€æ–°AIå›å¤ï¼šæ¬¡é«˜ä¼˜å…ˆçº§
                priority = 9;
            } else if (distanceFromEnd <= 3) {
                // æœ€è¿‘2è½®å¯¹è¯ï¼šé«˜ä¼˜å…ˆçº§
                priority = 8;
            } else if (isFileMessage) {
                // æ–‡ä»¶æ¶ˆæ¯ï¼šä¸­ç­‰ä¼˜å…ˆçº§ï¼ˆé‡è¦ä½†ä¸èƒ½å‹è¿‡æ–°é—®é¢˜ï¼‰
                priority = 5;
            } else {
                // æ™®é€šå†å²å¯¹è¯ï¼šä½ä¼˜å…ˆçº§
                priority = 1;
            }
            
            return {
                index: idx,
                message: msg,
                tokens: tokens,
                isFileMessage: isFileMessage,
                distanceFromEnd: distanceFromEnd,
                priority: priority,
                role: msg.role
            };
        });
        
        console.log('æ¶ˆæ¯ä¼˜å…ˆçº§åˆ†æ:', messageAnalysis.map(m => 
            `${m.role}:${m.tokens}tokens(è·ä»Š${m.distanceFromEnd}æ­¥,${m.isFileMessage ? 'æ–‡ä»¶' : 'å¯¹è¯'},ä¼˜å…ˆçº§${m.priority})`
        ).join(', '));
        
        // æŒ‰ä¼˜å…ˆçº§æ’åºï¼Œä¼˜å…ˆçº§ä½çš„å…ˆåˆ é™¤ï¼Œä½†ç»å¯¹ä¿æŠ¤æœ€æ–°2æ¡æ¶ˆæ¯
        const absoluteProtectionCount = Math.min(2, history.length); // ç»å¯¹ä¿æŠ¤æœ€æ–°2æ¡
        const sortedForDeletion = messageAnalysis
            .filter(m => m.distanceFromEnd >= absoluteProtectionCount) // ç»å¯¹ä¿æŠ¤æœ€æ–°æ¶ˆæ¯
            .sort((a, b) => a.priority - b.priority); // ä¼˜å…ˆçº§ä½çš„æ’å‰é¢
        
        let newHistory = [...history];
        let removedTokens = 0;
        
        // æ™ºèƒ½åˆ é™¤ç­–ç•¥ï¼šç¡®ä¿æœ€æ–°é—®é¢˜ä¸è¢«å†å²å†…å®¹å¹²æ‰°
        for (const analysis of sortedForDeletion) {
            if (getTotalTokens(newHistory) <= maxTokens) {
                break; // å·²ç»è¾¾åˆ°ç›®æ ‡
            }
            
            // å¦‚æœæ˜¯æ–‡ä»¶æ¶ˆæ¯ï¼Œé‡‡ç”¨æ›´ä¸¥æ ¼çš„æ¡ä»¶
            if (analysis.isFileMessage) {
                const currentOverage = getTotalTokens(newHistory) - maxTokens;
                const fileToTextRatio = analysis.tokens / totalTokens;
                
                // å¦‚æœå•ä¸ªæ–‡ä»¶æ¶ˆæ¯å æ¯”è¿‡å¤§ï¼ˆ>30%ï¼‰ï¼Œæˆ–è€…è¶…é™ä¸¥é‡ï¼ˆ>15Kï¼‰ï¼Œæ‰åˆ é™¤
                if (currentOverage > 15000 || fileToTextRatio > 0.3) {
                    console.warn(`åˆ é™¤å¤§æ–‡ä»¶æ¶ˆæ¯: ${analysis.tokens} tokens (å æ¯”${(fileToTextRatio*100).toFixed(1)}%, å½“å‰è¶…é™${currentOverage})`);
                } else {
                    console.log(`ä¿æŠ¤æ–‡ä»¶æ¶ˆæ¯: ${analysis.tokens} tokensï¼Œå½“å‰è¶…é™${currentOverage}ä¸è¶³ä»¥åˆ é™¤`);
                    continue;
                }
            }
            
            // åˆ é™¤è¿™æ¡æ¶ˆæ¯
            const messageIndex = newHistory.findIndex(m => m === analysis.message);
            if (messageIndex !== -1) {
                newHistory.splice(messageIndex, 1);
                removedTokens += analysis.tokens;
                console.log(`åˆ é™¤${analysis.isFileMessage ? 'æ–‡ä»¶' : 'å¯¹è¯'}æ¶ˆæ¯(è·ä»Š${analysis.distanceFromEnd}æ­¥): ${analysis.tokens} tokensï¼Œç´¯è®¡åˆ é™¤: ${removedTokens} tokens`);
            }
        }
        
        const finalTokens = getTotalTokens(newHistory);
        console.log(`æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†å®Œæˆ - åˆ é™¤: ${removedTokens} tokens, å‰©ä½™: ${finalTokens} tokens, ä¿ç•™: ${newHistory.length} æ¡æ¶ˆæ¯`);
        
        // åˆ†ææœ€ç»ˆä¿ç•™çš„æ¶ˆæ¯åˆ†å¸ƒ
        const finalFileMessages = newHistory.filter(msg => isMessageContainingFile(msg)).length;
        const recentMessages = newHistory.filter((msg, idx) => newHistory.length - 1 - idx < 4).length;
        console.log(`æœ€ç»ˆä¿ç•™: ${finalFileMessages} æ¡æ–‡ä»¶æ¶ˆæ¯, ${recentMessages} æ¡æœ€è¿‘å¯¹è¯`);
        
        // æ£€æŸ¥æ˜¯å¦æœ‰æ•ˆä¿æŠ¤äº†æœ€æ–°ç”¨æˆ·é—®é¢˜
        if (newHistory.length > 0) {
            const latestMessage = newHistory[newHistory.length - 1];
            if (latestMessage.role === 'user') {
                console.log(`âœ“ æœ€æ–°ç”¨æˆ·é—®é¢˜å·²ä¿æŠ¤ï¼Œå†…å®¹: "${getMessagePreview(latestMessage)}"`);
            }
        }
        
        // å¦‚æœè¿˜æ˜¯è¶…é™ï¼Œç»™å‡ºè¯¦ç»†è­¦å‘Š
        if (finalTokens > maxTokens) {
            console.warn(`è­¦å‘Šï¼šå³ä½¿æ™ºèƒ½åˆ é™¤åä»è¶…å‡ºé™åˆ¶ ${finalTokens - maxTokens} tokens`);
            console.warn('å»ºè®®ç”¨æˆ·å‡å°‘æ–‡ä»¶æ•°é‡æˆ–å°†å¤§æ–‡ä»¶åˆ†æ®µå¤„ç†');
        }
        
        return newHistory;
    }

    // è·å–æ¶ˆæ¯é¢„è§ˆçš„è¾…åŠ©å‡½æ•°
    function getMessagePreview(message) {
        if (typeof message.content === 'string') {
            return message.content.substring(0, 50) + (message.content.length > 50 ? '...' : '');
        } else if (Array.isArray(message.content)) {
            const textPart = message.content.find(part => part.type === 'text');
            if (textPart && textPart.text) {
                return textPart.text.substring(0, 50) + (textPart.text.length > 50 ? '...' : '');
            }
        }
        return '[æ¶ˆæ¯å†…å®¹æ— æ³•é¢„è§ˆ]';
    }

    // åˆ¤æ–­æ¶ˆæ¯æ˜¯å¦åŒ…å«æ–‡ä»¶å†…å®¹çš„è¾…åŠ©å‡½æ•°
    function isMessageContainingFile(message) {
        if (typeof message.content === 'string') {
            // æ£€æŸ¥æ˜¯å¦åŒ…å«æ–‡ä»¶å†…å®¹æ ‡è®°
            return message.content.includes('--- Content from file:') || 
                   message.content.includes('[ç”¨æˆ·ä¸Šä¼ äº†æ–‡ä»¶:') ||
                   message.content.includes('[ç”¨æˆ·ä¸Šä¼ äº†å›¾ç‰‡:') ||
                   message.content.includes('--- BEGIN FILE:');
        } else if (Array.isArray(message.content)) {
            // æ£€æŸ¥contentæ•°ç»„ä¸­æ˜¯å¦æœ‰æ–‡ä»¶ç›¸å…³å†…å®¹
            return message.content.some(part => {
                if (part.type === 'text' && part.text) {
                    return part.text.includes('--- Content from file:') || 
                           part.text.includes('[ç”¨æˆ·ä¸Šä¼ äº†æ–‡ä»¶:') ||
                           part.text.includes('[ç”¨æˆ·ä¸Šä¼ äº†å›¾ç‰‡:') ||
                           part.text.includes('--- BEGIN FILE:');
                }
                return false;
            });
        }
        return false;
    }

    // æ–°å¯¹è¯æŒ‰é’®äº‹ä»¶å¤„ç†
    newConversationBtn?.addEventListener('click', () => {
        // æ˜¾ç¤ºå½“å‰å¯¹è¯ç»Ÿè®¡
        const totalTokens = getTotalTokens(conversationHistory);
        const messageCount = conversationHistory.length;
        
        // æ¸…ç©ºå¯¹è¯å†å²
        conversationHistory = [];
        
        // æ¸…ç©ºèŠå¤©åŒºåŸŸ
        chatArea.innerHTML = '';
        
        // æ¸…ç©ºå·²é€‰æ–‡ä»¶
        selectedFiles = [];
        renderSelectedFiles();
        
        // æ¸…ç©ºè¾“å…¥æ¡†
        inputField.value = '';
        
        console.log(`å·²å¼€å§‹æ–°å¯¹è¯ã€‚æ¸…ç©ºäº† ${messageCount} æ¡æ¶ˆæ¯ï¼Œçº¦ ${totalTokens} ä¸ªtoken`);
        
        // åœ¨èŠå¤©åŒºåŸŸæ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯
        if (messageCount > 0) {
            appendMessage(`ğŸ”„ å·²å¼€å§‹æ–°å¯¹è¯\n\næ¸…ç©ºäº† ${messageCount} æ¡å†å²æ¶ˆæ¯ (çº¦ ${totalTokens.toLocaleString()} tokens)\n\nå¯ä»¥é‡æ–°ä¸Šä¼ æ–‡ä»¶æˆ–æé—®äº†ï¼`, 'ai');
        }
    });

    // Trigger file input click when upload button is clicked
    uploadFileButton.addEventListener('click', () => {
        fileUploadInput.accept = ".txt,.pdf,.doc,.docx,.xls,.xlsx,.jpeg,.jpg,.png,.csv,.wps"; // Add .wps
        fileUploadInput.click();
    });

    // Handle file selection
    fileUploadInput.addEventListener('change', (event) => {
        const newFiles = Array.from(event.target.files);
        let addedCount = 0;
        let duplicateCount = 0;
        
        // è¿½åŠ æ–°æ–‡ä»¶åˆ°å·²é€‰æ–‡ä»¶åˆ—è¡¨ï¼Œå¹¶å»é‡ï¼ˆåŸºäºæ–‡ä»¶åå’Œå¤§å°ï¼‰
        newFiles.forEach(newFile => {
            // æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„æ–‡ä»¶ï¼ˆé€šè¿‡æ–‡ä»¶åå’Œå¤§å°åˆ¤æ–­ï¼‰
            const isDuplicate = selectedFiles.some(existingFile => 
                existingFile.name === newFile.name && 
                existingFile.size === newFile.size
            );
            
            if (!isDuplicate) {
                selectedFiles.push(newFile);
                addedCount++;
            } else {
                duplicateCount++;
            }
        });
        
        // ç»™ç”¨æˆ·å‹å¥½çš„æç¤º
        if (duplicateCount > 0 && addedCount > 0) {
            console.log(`æ·»åŠ äº† ${addedCount} ä¸ªæ–°æ–‡ä»¶ï¼Œè·³è¿‡äº† ${duplicateCount} ä¸ªé‡å¤æ–‡ä»¶`);
        } else if (duplicateCount > 0 && addedCount === 0) {
            console.log(`æ‰€é€‰çš„ ${duplicateCount} ä¸ªæ–‡ä»¶å·²å­˜åœ¨ï¼Œæœªæ·»åŠ ä»»ä½•æ–°æ–‡ä»¶`);
        } else if (addedCount > 0) {
            console.log(`æˆåŠŸæ·»åŠ äº† ${addedCount} ä¸ªæ–‡ä»¶`);
        }
        
        // å¦‚æœæœ‰æ–°æ–‡ä»¶è¢«æ·»åŠ ï¼Œé‡ç½®å±•å¼€çŠ¶æ€
        if (newFiles.length > 0) {
            isFileListExpanded = false;
        }
        
        renderSelectedFiles();
        fileUploadInput.value = ''; // Reset file input to allow re-selecting the same file
    });

    function renderSelectedFiles() {
        selectedFilesContainer.innerHTML = '';
        if (selectedFiles.length === 0) {
            isFileListExpanded = false; // Ensure state is reset if no files
            return;
        }

        // æ·»åŠ æ–‡ä»¶æ•°é‡å’Œæ¸…ç©ºæŒ‰é’®çš„æ ‡é¢˜æ 
        const headerDiv = document.createElement('div');
        headerDiv.style.cssText = 'display: flex; justify-content: space-between; align-items: center; margin-bottom: 8px; padding: 4px 8px; background: rgba(79, 70, 229, 0.1); border-radius: 4px;';
        
        const fileCountSpan = document.createElement('span');
        fileCountSpan.textContent = `å·²é€‰æ‹© ${selectedFiles.length} ä¸ªæ–‡ä»¶`;
        fileCountSpan.style.cssText = 'font-size: 14px; color: #4F46E5; font-weight: 500;';
        
        const clearAllBtn = document.createElement('button');
        clearAllBtn.textContent = 'æ¸…ç©ºæ‰€æœ‰';
        clearAllBtn.style.cssText = 'padding: 2px 8px; font-size: 12px; background: #ef4444; color: white; border: none; border-radius: 3px; cursor: pointer;';
        clearAllBtn.title = 'æ¸…ç©ºæ‰€æœ‰å·²é€‰æ–‡ä»¶';
        clearAllBtn.onclick = () => {
            selectedFiles.length = 0; // æ¸…ç©ºæ•°ç»„
            isFileListExpanded = false;
            renderSelectedFiles();
        };
        
        headerDiv.appendChild(fileCountSpan);
        headerDiv.appendChild(clearAllBtn);
        selectedFilesContainer.appendChild(headerDiv);

        const list = document.createElement('ul');
        const filesToRender = isFileListExpanded ? selectedFiles : selectedFiles.slice(0, maxInitialFilesToShow);

        filesToRender.forEach(file => {
            const listItem = document.createElement('li');
            listItem.textContent = `${file.name} (${(file.size / 1024).toFixed(2)} KB)`;
            const removeBtn = document.createElement('button');
            removeBtn.textContent = 'x';
            removeBtn.onclick = () => {
                selectedFiles = selectedFiles.filter(f => f !== file);
                // If the list was expanded and now has fewer files than maxInitial, 
                // or if it becomes empty, reset expansion or re-render correctly.
                if (selectedFiles.length <= maxInitialFilesToShow) {
                    isFileListExpanded = false;
                }
                renderSelectedFiles();
            };
            listItem.appendChild(removeBtn);
            list.appendChild(listItem);
        });
        selectedFilesContainer.appendChild(list);

        if (selectedFiles.length > maxInitialFilesToShow) {
            const toggleBtn = document.createElement('button');
            toggleBtn.classList.add('toggle-file-list-btn'); // Add class for styling
            if (isFileListExpanded) {
                toggleBtn.textContent = 'æ”¶èµ·';
            } else {
                toggleBtn.textContent = `è¿˜æœ‰ ${selectedFiles.length - maxInitialFilesToShow} ä¸ªæ–‡ä»¶... (ç‚¹å‡»å±•å¼€)`;
            }
            toggleBtn.onclick = () => {
                isFileListExpanded = !isFileListExpanded;
                renderSelectedFiles();
            };
            selectedFilesContainer.appendChild(toggleBtn);
        }
    }

    // Send message when Send button is clicked
    sendButton.addEventListener('click', sendMessage);

    // Send message when Enter key is pressed in input field
    inputField.addEventListener('keypress', (event) => {
        if (event.key === 'Enter' && !event.shiftKey) {
            event.preventDefault(); // Prevent new line
            sendMessage();
        }
    });

    // Example: Log when mic button is clicked
    if (micButton) {
        // Web Speech API setup
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let recognition;
        const originalPlaceholder = inputField.placeholder; // Store original placeholder

        if (SpeechRecognition) {
            recognition = new SpeechRecognition();
            recognition.continuous = false; // Stop after first pause
            recognition.lang = 'zh-CN'; // Set language to Chinese
            recognition.interimResults = false; // Get final results
            recognition.maxAlternatives = 1;

            // Custom flag to track if recognition is active
            let recognitionIsActive = false;

        micButton.addEventListener('click', () => {
                if (recognitionIsActive) {
                    recognition.stop(); // Request to stop
                    // UI updates (placeholder, button style) handled by onend or onerror
                } else {
                    try {
                        inputField.value = ""; // Clear input field before starting
                        inputField.placeholder = "æ­£åœ¨è†å¬ï¼Œè¯·è¯´è¯..."; // Immediate feedback
                        micButton.classList.add('recording'); // Immediate visual feedback
                        micButton.title = "åœæ­¢å½•éŸ³";
                        recognition.start();
                        // Further UI updates will be handled by onstart if successful
                    } catch (e) {
                        console.error("Speech recognition start error immediately caught:", e);
                        appendMessage("æ— æ³•å¯åŠ¨è¯­éŸ³è¯†åˆ«: " + e.message, 'ai');
                        recognitionIsActive = false; // Ensure state is correct
                        micButton.classList.remove('recording');
                        micButton.title = "è¯­éŸ³è¾“å…¥";
                        inputField.placeholder = originalPlaceholder; // Restore placeholder on error
                    }
                }
            });

            recognition.onstart = () => {
                console.log('Voice recognition actually started.');
                recognitionIsActive = true;
                // UI updated in click handler for immediate feedback, confirm here or adjust if needed
                micButton.classList.add('recording');
                micButton.title = "åœæ­¢å½•éŸ³";
                inputField.placeholder = "æ­£åœ¨è†å¬ï¼Œè¯·è¯´è¯...";
            };

            recognition.onresult = (event) => {
                const transcript = event.results[0][0].transcript;
                inputField.value = inputField.value ? inputField.value + ' ' + transcript : transcript;
                inputField.focus(); // Focus on input field after transcript
                // Placeholder will be restored by onend
            };

            recognition.onerror = (event) => {
                console.error('Speech recognition error', event.error);
                let errorMessage = 'è¯­éŸ³è¯†åˆ«å‘ç”Ÿé”™è¯¯';
                if (event.error === 'no-speech') {
                    errorMessage = 'æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¯·é‡è¯•ã€‚';
                } else if (event.error === 'audio-capture') {
                    errorMessage = 'æ— æ³•æ•è·éº¦å…‹é£éŸ³é¢‘ï¼Œè¯·æ£€æŸ¥æƒé™ã€‚';
                } else if (event.error === 'not-allowed') {
                    errorMessage = 'éº¦å…‹é£æƒé™æœªæˆäºˆæˆ–è¢«é˜»æ­¢ã€‚';
                } else if (event.error === 'aborted') {
                    errorMessage = 'è¯­éŸ³è¯†åˆ«å·²ä¸­æ­¢ã€‚'; // Common if stopped manually or by short silence
                } else if (event.error === 'network') {
                    errorMessage = 'è¯­éŸ³è¯†åˆ«ç½‘ç»œé”™è¯¯ã€‚';
                } else if (event.error === 'service-not-allowed') {
                    errorMessage = 'è¯­éŸ³è¯†åˆ«æœåŠ¡æœªæˆæƒã€‚';
                }
                // Only show error in chat if it's not a simple abort or no-speech after a stop command
                if (event.error !== 'aborted' && event.error !== 'no-speech') {
                    appendMessage(errorMessage, 'ai');
                }
                // onend will also be called, so UI updates (placeholder, button) are handled there
            };

            recognition.onend = () => {
                console.log('Voice recognition ended.');
                recognitionIsActive = false;
                micButton.classList.remove('recording');
                micButton.title = "è¯­éŸ³è¾“å…¥";
                inputField.placeholder = originalPlaceholder; // Restore original placeholder
            };
            
        } else {
            micButton.disabled = true;
            micButton.title = "æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«";
            console.warn('Speech Recognition not supported by this browser.');
            // Optionally inform the user that the feature is not available
            // appendMessage('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«åŠŸèƒ½ã€‚', 'ai');
        }
    }

    // Function to append messages to the chat area
    function appendMessage(text, sender, messageId) {
        let messageElement = messageId ? document.getElementById(messageId) : null;
        let textNodeP;
        let iconContainer;

        const userSvgIcon = `<svg viewBox="0 0 24 24" fill="currentColor" style="width: 20px; height: 20px; margin-right: 8px;"><path d="M12 12c2.21 0 4-1.79 4-4s-1.79-4-4-4-4 1.79-4 4 1.79 4 4 4zm0 2c-2.67 0-8 1.34-8 4v2h16v-2c0-2.66-5.33-4-8-4z"></path></svg>`;
        const aiSvgIcon = `<svg width="24" height="24" viewBox="0 0 64 64" fill="none" xmlns="http://www.w3.org/2000/svg" style="margin-right: 8px;"> <rect x="12" y="16" width="40" height="32" rx="8" fill="#4F46E5"/> <circle cx="24" cy="32" r="4" fill="white"/> <circle cx="40" cy="32" r="4" fill="white"/> <path d="M20 48c2 4 8 6 12 6s10-2 12-6" stroke="white" stroke-width="2" stroke-linecap="round"/> <path d="M32 10v6" stroke="#4F46E5" stroke-width="4" stroke-linecap="round"/> <circle cx="32" cy="10" r="4" fill="#4F46E5"/></svg>`;

        if (messageElement) { // Updating an existing message
            iconContainer = messageElement.querySelector('.message-icon'); // Icon should already exist
            textNodeP = messageElement.querySelector('p');
            
            // If for some reason p tag is missing (should not happen with correct initial creation)
            if (!textNodeP) {
                textNodeP = document.createElement('p');
                if (iconContainer && iconContainer.nextSibling) {
                    messageElement.insertBefore(textNodeP, iconContainer.nextSibling);
                } else if (iconContainer) {
                    messageElement.appendChild(textNodeP);
                } else { // Should not happen if icon is always there for AI messages
                    messageElement.appendChild(textNodeP);
                }
            }
        } else { // Creating a new message
            messageId = sender + '-' + Date.now();
            messageElement = document.createElement('div');
            messageElement.id = messageId;
        messageElement.classList.add('message', `${sender}-message`);
        
            iconContainer = document.createElement('span');
            iconContainer.classList.add('message-icon');
            iconContainer.innerHTML = sender === 'user' ? userSvgIcon : aiSvgIcon;
            messageElement.appendChild(iconContainer);

            textNodeP = document.createElement('p');
            messageElement.appendChild(textNodeP);
            
            if (chatArea) {
        chatArea.appendChild(messageElement);
            } else {
                console.error("Chat area not found for new message!");
                return null;
            }
        }

        // Update text content
        if (sender === 'ai' && typeof marked !== 'undefined') {
            const markdownInput = (text === null || typeof text === 'undefined') ? '' : String(text);
            textNodeP.innerHTML = marked.parse(markdownInput); // Render Markdown for AI
        } else {
            textNodeP.textContent = (text === null || typeof text === 'undefined') ? '' : String(text); // Plain text for user or if marked is not available
        }
        
        // Manage 'ai-thinking' class correctly for new or updated messages
        if (sender === 'ai-thinking') {
            if (!messageElement.classList.contains('ai-thinking')) {
            messageElement.classList.add('ai-thinking');
            }
        } else {
            // If it's a normal AI message (not thinking), ensure thinking class is removed
            // This is important if a thinking message bubble is being updated to a real AI message
            if (sender === 'ai' && messageElement.classList.contains('ai-thinking')){
                messageElement.classList.remove('ai-thinking');
            }
        }

        if (chatArea) chatArea.scrollTop = chatArea.scrollHeight;
        return messageId; 
    }

    function removeThinking() {
        const thinkingElements = chatArea.querySelectorAll('.ai-thinking');
        thinkingElements.forEach(el => el.remove());
    }

    async function getActiveModel() {
        const res = await fetch('/api/models/active');
        if (!res.ok) return null;
        return await res.json();
    }

    async function sendMessage() {
        const userInput = inputField.value.trim();
        // Allow sending message if there is text input or files selected
        if (!userInput && selectedFiles.length === 0) return;

        // Use placeholder if input is empty but files are present
        const displayUserMessage = userInput || (selectedFiles.length > 0 ? "[å‘é€æ–‡ä»¶ä¸­...]" : "");
        if(displayUserMessage) appendMessage(displayUserMessage, 'user');
        
        inputField.value = '';
        // Create thinking message and store its ID
        const thinkingMessageId = appendMessage('AIæ­£åœ¨æ€è€ƒ...', 'ai-thinking'); 

        try {
            const activeModel = await getActiveModel();
            if (!activeModel) {
                removeThinking();
                appendMessage('é”™è¯¯ï¼šæ²¡æœ‰æ¿€æ´»çš„æ¨¡å‹ã€‚', 'ai');
                return;
            }

            let userMessageContentParts = [];
            if (userInput) {
                userMessageContentParts.push({ type: 'text', text: userInput });
            }
            
            const fileAttachmentsForRequestBody = []; // For non-image base64 data for 'attachments' field

            if (selectedFiles.length > 0) {
                const filePromises = selectedFiles.map(file => {
                    return new Promise((resolve, reject) => {
                        const reader = new FileReader();
                        reader.onload = () => resolve({ name: file.name, type: file.type, content: reader.result, file_obj: file });
                        reader.onerror = reject;

                        if (file.type.startsWith('image/')) {
                            reader.readAsDataURL(file); // Base64 for images
                        } else if (file.type === 'text/plain') {
                            reader.readAsText(file); // Text for .txt
                        } else if ([
                            'application/pdf',
                            'application/msword', // .doc
                            'application/vnd.openxmlformats-officedocument.wordprocessingml.document', // .docx
                            'application/vnd.ms-excel', // .xls
                            'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', // .xlsx
                            'text/csv',
                            'application/vnd.ms-works', // Common MIME for .wps, though often generic
                            // Add other potential WPS MIME types if known, or rely on extension for backend.
                            // For files not matching specific MIME types but ending with .wps, we can still try backend processing.
                            (file.name.toLowerCase().endsWith('.wps') && !file.type) // If no specific MIME but ends with .wps
                        ].includes(file.type) || file.name.toLowerCase().endsWith('.wps')) { // Also check extension directly
                            reader.readAsDataURL(file); // Base64 for these document types, including WPS
                        } else {
                            console.warn(`Unsupported file type from browser: ${file.name} (${file.type}). Trying to read as Base64 for backend processing.`);
                            // Fallback for unknown types, potentially including CSV if MIME type isn't 'text/csv'
                            // The backend will have the final say on processing based on filename/content.
                            reader.readAsDataURL(file);
                        }
                    });
                });

                const processedFiles = await Promise.all(filePromises);
                let textFileCombinedContent = "";

                for (const pf of processedFiles) {
                    if (pf.error) {
                        appendMessage(`æ— æ³•å¤„ç†æ–‡ä»¶ ${pf.name}: ${pf.error}`, 'ai');
                        continue;
                    }
                    if (!pf.content) continue;

                    if (pf.type.startsWith('image/')) {
                        fileAttachmentsForRequestBody.push({
                            filename: pf.name,
                            mime_type: pf.type,
                            data: pf.content.split(',')[1] // Base64 data
                        });
                        const imagePlaceholder = `[ç”¨æˆ·ä¸Šä¼ äº†å›¾ç‰‡: ${pf.name} - å°†ç”±åç«¯OCRå¤„ç†]`;
                        if (userMessageContentParts.find(p => p.type === 'text')) {
                            userMessageContentParts.find(p => p.type === 'text').text += `\\n${imagePlaceholder}`;
                        } else {
                            userMessageContentParts.unshift({ type: 'text', text: imagePlaceholder });
                        }
                    } else if (pf.type === 'text/plain') {
                        textFileCombinedContent += `--- BEGIN FILE: ${pf.name} ---\n${pf.content}\n--- END FILE: ${pf.name} ---\n\n`;
                    } else { // PDF, DOCX, XLSX etc. as Base64
                        fileAttachmentsForRequestBody.push({
                            filename: pf.name,
                            mime_type: pf.type,
                            data: pf.content.split(',')[1] // Remove "data:...;base64," prefix
                        });
                        // Add a placeholder in the text message part
                        const filePlaceholder = `[ç”¨æˆ·ä¸Šä¼ äº†æ–‡ä»¶: ${pf.name}]`;
                        if (userMessageContentParts.find(p => p.type === 'text')) {
                            userMessageContentParts.find(p => p.type === 'text').text += `\n${filePlaceholder}`;
                        } else {
                            userMessageContentParts.unshift({ type: 'text', text: filePlaceholder });
                        }
                    }
                }
                
                if (textFileCombinedContent) {
                    if (userMessageContentParts.find(p => p.type === 'text')){
                        userMessageContentParts.find(p => p.type === 'text').text = textFileCombinedContent + userMessageContentParts.find(p => p.type === 'text').text;
                    } else {
                        userMessageContentParts.unshift({ type: 'text', text: textFileCombinedContent });
                    }
                }
            }
            
            // Ensure there's at least one text part if other parts exist or if it was only files
            if (userMessageContentParts.length > 0 && !userMessageContentParts.find(p=>p.type === 'text')){
                 userMessageContentParts.unshift({ type: 'text', text: "[å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶]" });
            } else if (userMessageContentParts.length === 0 && selectedFiles.length > 0){
                 userMessageContentParts.push({ type: 'text', text: "[å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶]" });
            }
            
            // å°†å½“å‰ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°å¯¹è¯å†å²
            const currentUserMessage = { role: 'user', content: userMessageContentParts };
            conversationHistory.push(currentUserMessage);
            
            // æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†ï¼šåŸºäºtokenæ•°é‡è€Œä¸æ˜¯è½®æ•°
            const MAX_CONTEXT_TOKENS = 120000; // ä¿ç•™ä¸€äº›ä½™é‡ï¼Œä¸ç”¨æ»¡128K
            conversationHistory = manageContextLength(conversationHistory, MAX_CONTEXT_TOKENS);
            
            // å‘é€åŒ…å«å†å²è®°å½•çš„å®Œæ•´æ¶ˆæ¯
            await fetchLLMReply(activeModel, conversationHistory, fileAttachmentsForRequestBody, thinkingMessageId);
            
            selectedFiles = []; // Clear files after sending
            renderSelectedFiles(); // Update UI

        } catch (error) {
            removeThinking();
            appendMessage(`é”™è¯¯: ${error.message}`, 'ai');
            console.error("Detailed error:", error);
        }
    }

    async function fetchLLMReply(model, messages, attachments, baseMessageId) { // Renamed thinkingMessageId to baseMessageId for clarity
        // æ ¹æ®æ¨¡å‹ç±»å‹é€‚é…ä¸åŒAPI
        if (model.type === 'openrouter') {
            return await callOpenRouter(model, messages, attachments, baseMessageId);
        } else if (model.type === 'ollama') {
            // Ollama might not support complex message structures or attachments directly in this way.
            // For simplicity, we'll just send the first text part if available.
            const simpleTextInput = messages[0]?.content?.find(p => p.type === 'text')?.text || '';
            return await callOllama(model, simpleTextInput);
        } else if (model.type === 'telcom') {
            // Similar to Ollama, Telcom might expect simpler input.
            const simpleTextInput = messages[0]?.content?.find(p => p.type === 'text')?.text || '';
            return await callTelcom(model, simpleTextInput);
        } else {
            throw new Error('æš‚ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: ' + model.type);
        }
    }

    // OpenRouter API
    function cleanupExcessiveWhitespace(text) {
        const cleanedText = text.replace(/\n{3,}/g, '\n\n');
        return cleanedText.replace(/^\s+/, '');
    }

    async function callOpenRouter(model, messages, attachments, baseMessageId) { // Renamed thinkingMessageId to baseMessageId for clarity
        try {
            const requestBody = {
                model: model.modelName,
                messages: messages,
                temperature: 0.7,
                max_tokens: 4000,
                // stream: true is now set by the backend /api/relay
            };

            if (attachments && attachments.length > 0) {
                requestBody.attachments = attachments;
            }

            const response = await fetch('/api/relay', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify(requestBody)
            });

            if (baseMessageId) {
                appendMessage('æ­£åœ¨æ¥æ”¶AIå›å¤...', 'ai', baseMessageId);
            } else {
                console.error("baseMessageId not provided to callOpenRouter");
                removeThinking();
                baseMessageId = appendMessage('æ­£åœ¨æ¥æ”¶AIå›å¤...', 'ai');
                if (!baseMessageId) return;
            }

            if (!response.ok) {
                const errorText = await response.text(); 
                console.error('API Relay Error:', response.status, errorText);
                try {
                    const errorJson = JSON.parse(errorText);
                    // Check if it's our specific file processing error from the backend
                    if (errorJson.errorType === 'fileProcessingError') {
                        appendMessage(errorJson.message || 'ä¸€ä¸ªæˆ–å¤šä¸ªæ–‡ä»¶å¤„ç†å¤±è´¥ã€‚', 'ai', baseMessageId);
                    } else if (errorJson.errorType === 'textTooLongError') {
                        // æ–‡æœ¬è¿‡é•¿é”™è¯¯çš„ç‰¹æ®Šå¤„ç†ï¼Œæ˜¾ç¤ºæ›´æ¸…æ™°çš„æç¤º
                        const currentLength = errorJson.currentLength || 0;
                        const maxLength = errorJson.maxLength || 163840;
                        const overageKB = Math.round((currentLength - maxLength) / 1024);
                        
                        let errorMsg = `âš ï¸ æ–‡æœ¬å†…å®¹è¿‡é•¿ï¼Œæ— æ³•å¤„ç†\n\n`;
                        errorMsg += `ğŸ“Š **å½“å‰æ–‡æœ¬é•¿åº¦**: ${currentLength.toLocaleString()} å­—ç¬¦\n`;
                        errorMsg += `ğŸ“ **æœ€å¤§æ”¯æŒé•¿åº¦**: ${maxLength.toLocaleString()} å­—ç¬¦\n`;
                        errorMsg += `ğŸ“ˆ **è¶…å‡ºé•¿åº¦**: ${(currentLength - maxLength).toLocaleString()} å­—ç¬¦ (çº¦ ${overageKB}KB)\n\n`;
                        errorMsg += `ğŸ’¡ **è§£å†³å»ºè®®**:\n`;
                        errorMsg += `â€¢ å‡å°‘ä¸Šä¼ çš„æ–‡ä»¶æ•°é‡\n`;
                        errorMsg += `â€¢ é€‰æ‹©è¾ƒå°çš„æ–‡ä»¶\n`;
                        errorMsg += `â€¢ å°†å¤§æ–‡ä»¶åˆ†æ®µå¤„ç†\n`;
                        errorMsg += `â€¢ åˆ é™¤ä¸å¿…è¦çš„æ–‡ä»¶å†…å®¹`;
                        
                        appendMessage(errorMsg, 'ai', baseMessageId);
                    } else if (errorJson.errorType === 'llmError') {
                        // å¤§æ¨¡å‹APIé”™è¯¯
                        let llmErrorMsg = `ğŸ¤– å¤§æ¨¡å‹APIé”™è¯¯\n\n`;
                        if (errorJson.error && errorJson.error.message) {
                            llmErrorMsg += `**é”™è¯¯ä¿¡æ¯**: ${errorJson.error.message}\n`;
                        } else if (errorJson.message) {
                            llmErrorMsg += `**é”™è¯¯ä¿¡æ¯**: ${errorJson.message}\n`;
                        }
                        if (errorJson.error && errorJson.error.code) {
                            llmErrorMsg += `**é”™è¯¯ä»£ç **: ${errorJson.error.code}\n`;
                        }
                        appendMessage(llmErrorMsg, 'ai', baseMessageId);
                    } else if (errorJson.errorType === 'configError') {
                        // é…ç½®é”™è¯¯
                        appendMessage(`âš™ï¸ é…ç½®é”™è¯¯: ${errorJson.message || 'æ¨¡å‹é…ç½®æœ‰è¯¯'}`, 'ai', baseMessageId);
                    } else { // Other backend errors (LLM, config, etc.)
                        appendMessage(`âŒ ç³»ç»Ÿé”™è¯¯: ${errorJson.message || errorJson.error || 'æœªçŸ¥é”™è¯¯'}`, 'ai', baseMessageId);
                    }
                } catch (e) { // If errorText is not JSON
                    appendMessage(`âŒ æœåŠ¡å™¨é”™è¯¯: ${errorText}`, 'ai', baseMessageId);
                }
                return; 
            }

            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            let accumulatedResponse = '';
            let ellipsisInterval = null; // Variable to hold the interval ID

            // Start ellipsis animation for "Receiving..." message
            if (baseMessageId) {
                let dotCount = 0;
                const baseText = "æ­£åœ¨æ¥æ”¶AIå›å¤";
                ellipsisInterval = setInterval(() => {
                    dotCount = (dotCount + 1) % 4; // 0, 1, 2, 3
                    const dots = Array(dotCount).fill('.').join(''); // '', '.', '..', '...'
                    // Update the message content with animated ellipsis
                    // We pass 'ai-receiving' as sender to prevent marked.parse if text hasn't changed much
                    // and to potentially style it differently if needed, though appendMessage currently doesn't use it beyond 'ai' or 'user' for markdown.
                    appendMessage(baseText + dots, 'ai', baseMessageId);
                }, 500); // Adjust speed as needed
            }

            function processStream() {
                reader.read().then(({ done, value }) => {
                    if (done) {
                        clearInterval(ellipsisInterval); 
                        appendMessage(accumulatedResponse, 'ai', baseMessageId);
                        
                        // å°†AIå›å¤æ·»åŠ åˆ°å¯¹è¯å†å²
                        if (accumulatedResponse && accumulatedResponse.trim()) {
                            conversationHistory.push({ 
                                role: 'assistant', 
                                content: accumulatedResponse.trim() 
                            });
                        }
                        return;
                    }

                    const chunk = decoder.decode(value, { stream: true });
                    const lines = chunk.split('\n');
                    let hasNewContent = false; // Flag to check if this chunk added visible content

                    for (const line of lines) {
                        if (line.startsWith('data: ')) {
                            const jsonStr = line.substring(6);
                            if (jsonStr.trim() === '[DONE]') {
                                clearInterval(ellipsisInterval);
                                appendMessage(accumulatedResponse, 'ai', baseMessageId); // Final update
                                
                                // å°†AIå›å¤æ·»åŠ åˆ°å¯¹è¯å†å²
                                if (accumulatedResponse && accumulatedResponse.trim()) {
                                    conversationHistory.push({ 
                                        role: 'assistant', 
                                        content: accumulatedResponse.trim() 
                                    });
                                }
                                return;
                            }
                            try {
                                const parsed = JSON.parse(jsonStr);
                                
                                // æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯å“åº”
                                if (parsed.error) {
                                    clearInterval(ellipsisInterval);
                                    let errorMsg = `ğŸ¤– å¤§æ¨¡å‹è¿”å›é”™è¯¯\n\n`;
                                    if (parsed.error.message) {
                                        errorMsg += `**é”™è¯¯ä¿¡æ¯**: ${parsed.error.message}\n`;
                                    }
                                    if (parsed.error.code) {
                                        errorMsg += `**é”™è¯¯ä»£ç **: ${parsed.error.code}\n`;
                                    }
                                    if (parsed.error.type) {
                                        errorMsg += `**é”™è¯¯ç±»å‹**: ${parsed.error.type}\n`;
                                    }
                                    appendMessage(errorMsg, 'ai', baseMessageId);
                                    return;
                                }
                                
                                // å¤„ç†ç‰¹æ®Šçš„processed_user_messageï¼Œæ›´æ–°å¯¹è¯å†å²ä¸­çš„ç”¨æˆ·æ¶ˆæ¯
                                if (parsed.type === 'processed_user_message') {
                                    // æ‰¾åˆ°æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯å¹¶æ›¿æ¢ä¸ºå¤„ç†åçš„å®Œæ•´å†…å®¹
                                    for (let i = conversationHistory.length - 1; i >= 0; i--) {
                                        if (conversationHistory[i].role === 'user') {
                                            conversationHistory[i] = parsed.message;
                                            break;
                                        }
                                    }
                                    console.log('å·²æ›´æ–°å¯¹è¯å†å²ä¸­çš„ç”¨æˆ·æ¶ˆæ¯ï¼ŒåŒ…å«å®Œæ•´æ–‡ä»¶å†…å®¹');
                                    continue; // è·³è¿‡è¿™ä¸ªç‰¹æ®Šæ¶ˆæ¯çš„å…¶ä»–å¤„ç†
                                }
                                
                                if (parsed.choices && parsed.choices[0] && parsed.choices[0].delta && parsed.choices[0].delta.content) {
                                    accumulatedResponse += parsed.choices[0].delta.content;
                                    hasNewContent = true; 
                                }
                            } catch (e) {
                                console.warn('Error parsing stream JSON:', jsonStr, e);
                            }
                        }
                    }

                    // If new content was actually added, stop ellipsis and update message with content
                    if (hasNewContent) {
                        if (ellipsisInterval) {
                            clearInterval(ellipsisInterval);
                            ellipsisInterval = null; 
                        }
                        appendMessage(accumulatedResponse, 'ai', baseMessageId); 
                    } else if (!ellipsisInterval && !done) {
                        // If ellipsis was stopped but there's no new content yet (e.g. empty data chunks) and not done,
                        // potentially restart it or ensure the "Receiving..." message stays without dots if preferred.
                        // For now, we do nothing, relying on the interval to continue if it wasn't cleared.
                    }

                    if (!done) {
                        processStream(); 
                    }
                }).catch(err => {
                    clearInterval(ellipsisInterval); // Stop ellipsis on error
                    console.error('Error reading stream from /api/relay:', err);
                    appendMessage('è¯»å–å›å¤æµæ—¶å‡ºé”™ã€‚', 'ai', baseMessageId);
                });
            }
            processStream(); // Start processing the stream
            
            // Since we are streaming, this function no longer returns the full AI reply directly.
            // The reply is appended to the DOM reactively.
            return; // Or return a promise that resolves when stream is done, if needed elsewhere

        } catch (error) {
            console.error('callOpenRouter Fetch/Setup Error:', error);
            // If an error occurs, ensure ellipsisInterval is cleared if it was started
            if (ellipsisInterval) {
                 clearInterval(ellipsisInterval);
            }
            if (baseMessageId) {
                appendMessage(`è°ƒç”¨OpenRouterå‡ºé”™: ${error.message}`, 'ai', baseMessageId);
            } else {
                removeThinking(); // Fallback if no baseMessageId
                appendMessage(`è°ƒç”¨OpenRouterå‡ºé”™: ${error.message}`, 'ai');
            }
        }
    }

    // Ollama API
    async function callOllama(model, userInput) {
        const res = await fetch(model.apiUrl + '/api/chat', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                model: model.modelName,
                messages: [
                    { role: 'user', content: userInput }
                ]
            })
        });
        if (!res.ok) throw new Error('Ollamaè¯·æ±‚å¤±è´¥');
        const data = await res.json();
        return data.message?.content || '[æ— å›å¤]';
    }

    // Telcom DeepSeek API
    async function callTelcom(model, userInput) {
        const res = await fetch(model.apiUrl, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                model: model.modelName,
                messages: [
                    { role: 'user', content: userInput }
                ]
            })
        });
        if (!res.ok) throw new Error('Telcomè¯·æ±‚å¤±è´¥');
        const data = await res.json();
        return data.choices?.[0]?.message?.content || '[æ— å›å¤]';
    }
}); 